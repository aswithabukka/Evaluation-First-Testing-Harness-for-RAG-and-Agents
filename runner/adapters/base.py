"""
RAGAdapter — the single interface any RAG pipeline must implement.

Users subclass RAGAdapter in their own project and point rageval.yaml at it.
The harness calls setup(), then run() for each test case, then teardown().
"""
from abc import ABC, abstractmethod
from dataclasses import dataclass, field


@dataclass
class ToolCall:
    tool: str
    args: dict = field(default_factory=dict)
    result: dict | None = None


@dataclass
class PipelineOutput:
    """
    Everything returned by a single pipeline invocation.

    answer            — the text response generated by the pipeline
    retrieved_contexts — list of context strings retrieved (for Ragas faithfulness)
    tool_calls        — tool invocations made during the run (for rule evaluation)
    turn_history      — full conversation so far (for multi-turn agent evaluation)
    metadata          — arbitrary dict for pipeline-specific debugging info
    """

    answer: str
    retrieved_contexts: list[str] = field(default_factory=list)
    tool_calls: list[ToolCall] = field(default_factory=list)
    turn_history: list[dict] = field(default_factory=list)
    metadata: dict = field(default_factory=dict)


class RAGAdapter(ABC):
    """
    Abstract base class for plugging any RAG pipeline into the harness.

    Minimal implementation — only run() is required:

        class MyPipeline(RAGAdapter):
            def run(self, query: str, context: dict) -> PipelineOutput:
                answer = self.llm.ask(query)
                return PipelineOutput(answer=answer, retrieved_contexts=[...])

    For pipelines that require initialisation (loading models, connecting to
    vector stores, etc.), override setup() and teardown().
    """

    def setup(self) -> None:
        """Called once before the evaluation run starts. Load models, connect clients."""
        pass

    @abstractmethod
    def run(self, query: str, context: dict) -> PipelineOutput:
        """
        Execute the pipeline for a single query.

        Args:
            query:   The user query from the test case.
            context: The JSONB context dict from the test case (may be empty).
                     Use this to pass retrieval hints or pipeline configuration.

        Returns:
            PipelineOutput with at minimum an answer string.
        """
        ...

    def teardown(self) -> None:
        """Called once after the evaluation run completes. Clean up resources."""
        pass
