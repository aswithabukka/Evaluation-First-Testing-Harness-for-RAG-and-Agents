"""Writes the structured evaluation report to a JSON file or stdout."""
import json
import sys


def write_report(report: dict, output_path: str | None = None) -> None:
    content = json.dumps(report, indent=2, default=str)
    if output_path:
        with open(output_path, "w") as f:
            f.write(content)
    else:
        sys.stdout.write(content + "\n")


def format_as_github_pr_comment(report: dict) -> str:
    """Returns a Markdown string suitable for posting as a GitHub PR comment."""
    run = report.get("run", {})
    summary = report.get("summary", {})
    gate = report.get("gate", {})
    diff = report.get("diff", {})

    lines = ["## RAG Evaluation Results\n"]

    # Run metadata
    lines.append(f"**Run ID**: `{run.get('id', 'N/A')}`  ")
    lines.append(f"**Commit**: `{run.get('git_commit_sha', 'N/A')}`  ")
    lines.append(f"**Branch**: `{run.get('git_branch', 'N/A')}`\n")

    # Metrics table
    lines.append("### Metrics\n")
    lines.append("| Metric | Score | Threshold | Status |")
    lines.append("|--------|-------|-----------|--------|")
    thresholds = run.get("gate_threshold_snapshot", {})
    metric_map = {
        "Faithfulness": ("avg_faithfulness", "faithfulness"),
        "Answer Relevancy": ("avg_answer_relevancy", "answer_relevancy"),
        "Context Precision": ("avg_context_precision", "context_precision"),
        "Context Recall": ("avg_context_recall", "context_recall"),
        "Pass Rate": ("pass_rate", "pass_rate"),
    }
    for label, (summary_key, threshold_key) in metric_map.items():
        value = summary.get(summary_key)
        threshold = thresholds.get(threshold_key, 0.7)
        if value is not None:
            status = "✅ PASS" if value >= threshold else "❌ FAIL"
            lines.append(f"| {label} | {value:.3f} | {threshold:.2f} | {status} |")

    # Gate decision
    if gate:
        gate_status = "✅ **APPROVED**" if gate.get("passed") else "❌ **BLOCKED**"
        lines.append(f"\n### Release Gate: {gate_status}\n")

    # Regressions
    regressions = diff.get("regressions", []) if diff else []
    if regressions:
        lines.append(f"### ⚠️ {len(regressions)} Regression(s) Detected\n")
        lines.append("| Query | Failure Reason |")
        lines.append("|-------|----------------|")
        for reg in regressions[:10]:
            query = reg.get("query", "")[:60].replace("|", "\\|")
            reason = (reg.get("failure_reason") or "unknown")[:80].replace("|", "\\|")
            lines.append(f"| {query} | {reason} |")
        if len(regressions) > 10:
            lines.append(f"\n_...and {len(regressions) - 10} more_")

    lines.append("\n---")
    lines.append("_Generated by [RAG Eval Harness](https://github.com/your-org/rag-eval-harness)_")

    return "\n".join(lines)
